# Step 1: Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
import joblib

# Step 2: Load the data
file_path = r"C:\Users\hp\Desktop\AnomaData.csv.xlsx"
xls = pd.ExcelFile(file_path)
data = pd.read_excel(xls, sheet_name='Sheet1')

# Step 3: Data Cleaning
# Remove the duplicate 'y.1' column (if present)
data_cleaned = data.drop(columns=['y.1'], errors='ignore')

# Convert the 'time' column to datetime format
data_cleaned['time'] = pd.to_datetime(data_cleaned['time'])

# Check for missing values
missing_values = data_cleaned.isnull().sum()
print("Missing values in each column:\n", missing_values)

# Step 4: Exploratory Data Analysis (EDA)

# Plot the distribution of the target variable 'y'
plt.figure(figsize=(6, 4))
sns.countplot(x='y', data=data_cleaned, hue='y', palette='Set2', legend=False)
plt.title('Distribution of Anomalies (Target Variable)')
plt.xlabel('Anomaly (y)')
plt.ylabel('Count')
plt.show()

# Plot the distribution of a feature (e.g., 'x1')
plt.figure(figsize=(6, 4))
sns.histplot(data_cleaned['x1'], bins=30, kde=True, color='blue')
plt.title('Distribution of Feature x1')
plt.xlabel('x1')
plt.ylabel('Frequency')
plt.show()

# Step 5: Check for outliers using a boxplot (for feature 'x1')
plt.figure(figsize=(6, 4))
sns.boxplot(data=data_cleaned, x='x1', color='skyblue')
plt.title('Boxplot of Feature x1')
plt.xlabel('x1')
plt.show()

# Step 5 (optional): Remove outliers using the IQR method (for 'x1')
Q1 = data_cleaned['x1'].quantile(0.25)
Q3 = data_cleaned['x1'].quantile(0.75)
IQR = Q3 - Q1

# Remove outliers
data_cleaned = data_cleaned[~((data_cleaned['x1'] < (Q1 - 1.5 * IQR)) | (data_cleaned['x1'] > (Q3 + 1.5 * IQR)))]

# Step 6: Feature scaling (excluding 'y' and 'time' columns)
scaler = StandardScaler()

# Select feature columns (excluding 'y' and 'time')
feature_cols = data_cleaned.drop(columns=['y', 'time']).columns

# Apply StandardScaler
data_cleaned[feature_cols] = scaler.fit_transform(data_cleaned[feature_cols])

# Step 7: Split the data into train and test sets
X = data_cleaned.drop(columns=['y', 'time'])  # Features
y = data_cleaned['y']  # Target

# 70% training, 30% testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Step 8: Train a Logistic Regression model
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Step 9: Evaluate model performance
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Display classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Display confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Step 10: Hyperparameter tuning using GridSearchCV
param_grid = {
    'C': [0.1, 1.0, 10.0],  # Regularization strength
    'solver': ['lbfgs', 'liblinear']
}

grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Display the best hyperparameters
print("Best hyperparameters:", grid_search.best_params_)

# Evaluate the best model
best_model = grid_search.best_estimator_
y_pred_best = best_model.predict(X_test)
accuracy_best = accuracy_score(y_test, y_pred_best)
print(f"Accuracy after tuning: {accuracy_best * 100:.2f}%")

# Step 11: Save the model
model_filename = 'best_logistic_regression_model.pkl'
joblib.dump(best_model, model_filename)
print(f"Model saved to {model_filename}")

# Step 12: Load the saved model
loaded_model = joblib.load(model_filename)

# Make predictions with the loaded model
new_predictions = loaded_model.predict(X_test)

# Evaluate the loaded model
accuracy_loaded_model = accuracy_score(y_test, new_predictions)
print(f"Accuracy of loaded model: {accuracy_loaded_model * 100:.2f}%")

